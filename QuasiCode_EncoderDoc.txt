---------------------------------------------------------------------------------------+
  +-+-+---+-+-+ copytight by Kvazikot  +-+-+---+-+-+ 
  +-+-+ email: vsbaranov83@gmail.com 
  + - + - + github: http://github.com/Kvazikot/QuasiCode
  + - + - + --- + - + - + 
  Description on russian	
+ ------------------------------------------------- --------------------------------------- +

Посмотрим. Встроить какую-то логотипину и искажение типа дисторсии, рыбий глаз.
Задача состоит в следующем. 
Нужно разбить некий файл на части zip аржива.
Далее встроить эту информацию в яркостную и цветоразносную компоненту произвольного видео.
Для синхронизации данных можно использовать вставки из клеточного автомата разной степени.
Для генерации клеточного автомата нужно переписать live_gpu на Пайтоне так удобнее.
Так можно найти начало или определенный том архива среди большого количества видосов.
Посмотреть в сторону использования QR-кодов.
Скачать статьи по 4 step search алгоритму который я реализовывал в дипломном проекте.
Возможжно искать блоке в пространстве кругов разных радиусов.
Упростить цвета с помощью KNN алгоритма, перейти на упрощенные цвета.
Возможно слегка подгонять яркость блоков так чтобы при DCT блока цвет не сильно искажался.
Нужно чтобы енкодер был робастный относительно многократных пережатий видео.
Вставки в видео не должны сильно отвлекать зрителя.
Где-то можно использовать комбинацию алгоритмов.
Например можно выделять фичи такие как sift и распознавать перспективные искажения
или расчитывать искажения связанные с дисторсией картинки при переходе от кадра к кадру.
При смене алгоритма нужно вставлять какойто визуальный код например определенную стадию
клеточного автомата или qr код.
Клеточный автомат можно генерить с помощью двух ключей.
Первый ключ - инициальное состояние, второй - затравка для генератора шумов.
Необходимо чтобы алгоритм был устойчив к ошибкам и робастен относительно 
детекции наслоенных данных. 
На этапе подготовки данных нужно запаковать их в помехоустойчивый код.
Коды Хемминга или Рида Соломона.
Желательно генерировать наложение кода в реальном времени.
h.264 Level 3.1/4.1 muxed into an .flv and .mp4
The other codec used is VP8 which is coming in the WebM container format. WebM

На стр. 186 из 349 Iain E. Richardson - H264 (2nd edition) 
показано субпиксельное движение и предсказание макроблоеов в стандарте h264.
Модно сделать следующее:
Добавить два новых модуля qcencoder.py и qcdecoder.py
1. В QuasiCode.py 
Создать тестовое движение произвольного обьекта в кадре с субпиксельнрой точностью
2. Нарисовать сетку
3. Задать скорость движения тестового обьекта
4. Посмотреть как это все отрисовывается.
5. Вычислить SAD макроблоки 16x16 8x8 8x16
6. Предсказать маркоблоки по P и I кдрам (предыдущий и последующий)
7. Вычислить вектора движения.
8. Вносить изменения в исходные пикселы обьекта 
так чтобы отклонить вектора на заданный кодирующий данные вектор dv  
9. Построить векторное поле для макроблоков
10. Запаковать полученные кадры встроенным кодером
11. Отркыть видео в другом модуле


live_gpu.py 
Модуль для вычисления клеточного автомата 
Аналогично программе live_gpu, но на основе opencv.
Программа генерирует квадратное изображение произвольного размера.
Расчитывает следующее состояние клеточного автомата на основе текущего по правилам Конвея (1971).


qcencoder.py 
Вход - изображение с генератора клеточного автомата live_gpu.py
Выход - кадр видео
Закодировать поседовательность температур процессора во времени в кадр видео.
Первоначальная идея состоит в том вносить изменения в автомат добавляя новые клетки.
Новые клетки добавляются и цет их кодирует какой-то параметр например - температуру процессора
на момент генерации случайногого числа.

qcdecoder.py
Вход - видео закодированное qcencoder.py